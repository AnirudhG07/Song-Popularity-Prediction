{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947d6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error, \n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, roc_curve, confusion_matrix, classification_report)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c4f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (30000, 15)\n",
      "Test data shape: (10000, 14)\n",
      "\n",
      "Missing values in train data:\n",
      "id                     0\n",
      "song_duration_ms    3067\n",
      "acousticness        3024\n",
      "danceability        2967\n",
      "energy              2935\n",
      "instrumentalness    2966\n",
      "key                 3074\n",
      "liveness            3022\n",
      "loudness            2977\n",
      "audio_mode             0\n",
      "speechiness            0\n",
      "tempo                  0\n",
      "time_signature         0\n",
      "audio_valence          0\n",
      "song_popularity        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "id                     0\n",
      "song_duration_ms    1034\n",
      "acousticness         968\n",
      "danceability        1061\n",
      "energy              1040\n",
      "instrumentalness    1019\n",
      "key                  991\n",
      "liveness            1066\n",
      "loudness             980\n",
      "audio_mode             0\n",
      "speechiness            0\n",
      "tempo                  0\n",
      "time_signature         0\n",
      "audio_valence          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load train and test data\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(\"Train data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"\\nMissing values in train data:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Check the target variable distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['song_popularity'], bins=30, kde=True)\n",
    "plt.title('Distribution of Song Popularity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12057c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to binary classification (0/1) - you mentioned threshold around 0.37\n",
    "# Let's first analyze the optimal threshold\n",
    "def find_optimal_threshold(y_true, y_pred_proba):\n",
    "    \"\"\"Find optimal threshold using Youden's J statistic\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    j_scores = tpr - fpr\n",
    "    optimal_idx = np.argmax(j_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "def preprocess_data(df, is_train=True, imputer_dict=None, scaler_dict=None):\n",
    "    \"\"\"\n",
    "    Preprocess the data with proper handling for train/test sets\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Separate features and target if it's training data\n",
    "    if is_train:\n",
    "        X = df_processed.drop('song_popularity', axis=1)\n",
    "        y = df_processed['song_popularity']\n",
    "    else:\n",
    "        X = df_processed\n",
    "        y = None\n",
    "    \n",
    "    # Handle missing values\n",
    "    numerical_features = ['song_duration_ms', 'acousticness', 'danceability', 'energy', \n",
    "                         'instrumentalness', 'liveness', 'loudness', 'speechiness', \n",
    "                         'tempo', 'audio_valence']\n",
    "    \n",
    "    categorical_features = ['key', 'time_signature', 'audio_mode']\n",
    "    \n",
    "    # Initialize imputers if not provided\n",
    "    if imputer_dict is None:\n",
    "        imputer_dict = {\n",
    "            'num_imputer': KNNImputer(n_neighbors=5),\n",
    "            'cat_imputer': SimpleImputer(strategy='most_frequent')\n",
    "        }\n",
    "    \n",
    "    # Apply imputation\n",
    "    X[numerical_features] = imputer_dict['num_imputer'].fit_transform(X[numerical_features]) if is_train else imputer_dict['num_imputer'].transform(X[numerical_features])\n",
    "    X[categorical_features] = imputer_dict['cat_imputer'].fit_transform(X[categorical_features]) if is_train else imputer_dict['cat_imputer'].transform(X[categorical_features])\n",
    "    \n",
    "    # Feature engineering\n",
    "    X = create_features(X)\n",
    "    \n",
    "    # Scale numerical features\n",
    "    numerical_features_extended = [f for f in X.columns if f not in categorical_features + ['id']]\n",
    "    \n",
    "    if scaler_dict is None:\n",
    "        scaler_dict = {\n",
    "            'scaler': StandardScaler()\n",
    "        }\n",
    "    \n",
    "    X_scaled = scaler_dict['scaler'].fit_transform(X[numerical_features_extended]) if is_train else scaler_dict['scaler'].transform(X[numerical_features_extended])\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    X_final = pd.DataFrame(X_scaled, columns=numerical_features_extended, index=X.index)\n",
    "    X_final[categorical_features] = X[categorical_features].values\n",
    "    \n",
    "    return X_final, y, imputer_dict, scaler_dict\n",
    "\n",
    "def create_features(X):\n",
    "    \"\"\"Create additional features\"\"\"\n",
    "    X_featured = X.copy()\n",
    "    \n",
    "    # Interaction features\n",
    "    X_featured['energy_danceability'] = X_featured['energy'] * X_featured['danceability']\n",
    "    X_featured['valence_energy'] = X_featured['audio_valence'] * X_featured['energy']\n",
    "    X_featured['acoustic_energy'] = X_featured['acousticness'] * X_featured['energy']\n",
    "    X_featured['dance_valence'] = X_featured['danceability'] * X_featured['audio_valence']\n",
    "    \n",
    "    # Duration features\n",
    "    X_featured['duration_minutes'] = X_featured['song_duration_ms'] / 60000\n",
    "    X_featured['duration_seconds'] = X_featured['song_duration_ms'] / 1000\n",
    "    \n",
    "    # Loudness features\n",
    "    X_featured['loudness_abs'] = abs(X_featured['loudness'])\n",
    "    \n",
    "    # Tempo features\n",
    "    X_featured['tempo_category'] = pd.cut(X_featured['tempo'], \n",
    "                                        bins=[0, 60, 100, 140, 200, 300],\n",
    "                                        labels=[0, 1, 2, 3, 4])\n",
    "    X_featured['tempo_category'] = X_featured['tempo_category'].astype('category')\n",
    "    \n",
    "    # Energy ratio features\n",
    "    X_featured['energy_loudness_ratio'] = X_featured['energy'] / (abs(X_featured['loudness']) + 1)\n",
    "    \n",
    "    return X_featured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d67e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train features shape: (30000, 22)\n",
      "Processed test features shape: (10000, 22)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess training data\n",
    "X_train, y_train, imputer_dict, scaler_dict = preprocess_data(train_df, is_train=True)\n",
    "\n",
    "# Convert to binary classification - we'll find optimal threshold later\n",
    "# For initial training, use the original binary target\n",
    "y_train_binary = y_train\n",
    "\n",
    "# Preprocess test data using the same imputers and scaler from training\n",
    "X_test, y_test, _, _ = preprocess_data(test_df, is_train=False, \n",
    "                                      imputer_dict=imputer_dict, \n",
    "                                      scaler_dict=scaler_dict)\n",
    "\n",
    "print(\"Processed train features shape:\", X_train.shape)\n",
    "print(\"Processed test features shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5cb6f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Random Forest: AUC = 1.0000, Optimal Threshold = 0.6300, CV AUC = 0.5515 (±0.0027)\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting: AUC = 0.6695, Optimal Threshold = 0.3778, CV AUC = 0.5663 (±0.0065)\n",
      "Training XGBoost...\n",
      "XGBoost: AUC = 0.9796, Optimal Threshold = 0.3967, CV AUC = 0.5361 (±0.0064)\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 10932, number of negative: 19068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score -0.000000[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "LightGBM: AUC = 0.8838, Optimal Threshold = 0.5083, CV AUC = 0.5542 (±0.0062)\n",
      "Training CatBoost...\n",
      "CatBoost: AUC = 0.7938, Optimal Threshold = 0.3822, CV AUC = 0.5536 (±0.0050)\n",
      "Training Logistic Regression...\n",
      "Logistic Regression: AUC = 0.5546, Optimal Threshold = 0.4877, CV AUC = 0.5500 (±0.0087)\n",
      "Training SVM...\n",
      "SVM: AUC = 0.5912, Optimal Threshold = 0.3628, CV AUC = 0.5585 (±0.0075)\n",
      "\n",
      "Model Performance Summary:\n",
      "                     train_accuracy  train_precision  train_recall  train_f1  \\\n",
      "Gradient Boosting          0.630467         0.493920      0.572173  0.530175   \n",
      "SVM                        0.552200         0.420369      0.604098  0.495759   \n",
      "LightGBM                   0.794267         0.684553      0.807538  0.740977   \n",
      "CatBoost                   0.718700         0.599078      0.689444  0.641092   \n",
      "Random Forest              1.000000         1.000000      1.000000  1.000000   \n",
      "Logistic Regression        0.517733         0.398659      0.636206  0.490168   \n",
      "XGBoost                    0.923433         0.875533      0.920783  0.897588   \n",
      "\n",
      "                     train_auc  optimal_threshold  cv_mean_auc  cv_std_auc  \n",
      "Gradient Boosting     0.669537           0.377777     0.566292    0.006467  \n",
      "SVM                   0.591185           0.362845     0.558512    0.007487  \n",
      "LightGBM              0.883755           0.508254     0.554235    0.006219  \n",
      "CatBoost              0.793803           0.382223     0.553561    0.005037  \n",
      "Random Forest         1.000000           0.630000     0.551465    0.002740  \n",
      "Logistic Regression   0.554643           0.487697     0.549979    0.008661  \n",
      "XGBoost               0.979636           0.396677     0.536114    0.006407  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define multiple classification models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=200, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=200, random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight='balanced'),\n",
    "    'CatBoost': CatBoostClassifier(n_estimators=200, random_state=42, verbose=0),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, n_jobs=-1, class_weight='balanced', max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, probability=True, class_weight='balanced')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train_binary)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    optimal_threshold = find_optimal_threshold(y_train_binary, y_pred_proba)\n",
    "    y_pred_binary = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train_binary, y_pred_binary)\n",
    "    train_precision = precision_score(y_train_binary, y_pred_binary)\n",
    "    train_recall = recall_score(y_train_binary, y_pred_binary)\n",
    "    train_f1 = f1_score(y_train_binary, y_pred_binary)\n",
    "    train_auc = roc_auc_score(y_train_binary, y_pred_proba)\n",
    "    \n",
    "    # Cross-validation for AUC\n",
    "    cv_scores = cross_val_score(model, X_train, y_train_binary, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    results[name] = {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_precision': train_precision,\n",
    "        'train_recall': train_recall,\n",
    "        'train_f1': train_f1,\n",
    "        'train_auc': train_auc,\n",
    "        'optimal_threshold': optimal_threshold,\n",
    "        'cv_mean_auc': cv_scores.mean(),\n",
    "        'cv_std_auc': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}: AUC = {train_auc:.4f}, Optimal Threshold = {optimal_threshold:.4f}, CV AUC = {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(results_df.sort_values('cv_mean_auc', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f07467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10932, number of negative: 19068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 10932, number of negative: 19068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:45:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:45:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:45:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:45:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:45:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:46:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:46:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:46:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:46:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:46:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble: AUC = 0.9983, Optimal Threshold = 0.4319, CV AUC = 0.5593\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:55:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 8745, number of negative: 15255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of positive: 8746, number of negative: 15254\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:55:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:55:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[22:55:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:55:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6997, number of negative: 12203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6996, number of negative: 12204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4614\n",
      "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Stacking Ensemble: AUC = 0.7929, Optimal Threshold = 0.5101, CV AUC = 0.5675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create base models for ensemble\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')),\n",
    "    ('xgb', XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Voting Ensemble\n",
    "voting_ensemble = VotingClassifier(estimators=base_models, voting='soft', n_jobs=-1)\n",
    "voting_ensemble.fit(X_train, y_train_binary)\n",
    "\n",
    "# Stacking Ensemble\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "    n_jobs=-1,\n",
    "    stack_method='predict_proba'\n",
    ")\n",
    "stacking_ensemble.fit(X_train, y_train_binary)\n",
    "\n",
    "# Evaluate ensembles\n",
    "ensemble_results = {}\n",
    "for name, ensemble in [('Voting', voting_ensemble), ('Stacking', stacking_ensemble)]:\n",
    "    y_pred_proba = ensemble.predict_proba(X_train)[:, 1]\n",
    "    optimal_threshold = find_optimal_threshold(y_train_binary, y_pred_proba)\n",
    "    y_pred_binary = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    cv_scores = cross_val_score(ensemble, X_train, y_train_binary, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    ensemble_results[name] = {\n",
    "        'train_auc': roc_auc_score(y_train_binary, y_pred_proba),\n",
    "        'optimal_threshold': optimal_threshold,\n",
    "        'cv_mean_auc': cv_scores.mean(),\n",
    "        'cv_std_auc': cv_scores.std()\n",
    "    }\n",
    "    print(f\"{name} Ensemble: AUC = {roc_auc_score(y_train_binary, y_pred_proba):.4f}, Optimal Threshold = {optimal_threshold:.4f}, CV AUC = {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Add to results\n",
    "ensemble_results_df = pd.DataFrame(ensemble_results).T\n",
    "results_df = pd.concat([results_df, ensemble_results_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24f716c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost parameters: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "Best XGBoost AUC score: 0.5688344052955543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sub_6_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning for the best model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Use XGBoost for tuning\n",
    "xgb_tuned = RandomizedSearchCV(\n",
    "    XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_tuned.fit(X_train, y_train_binary)\n",
    "\n",
    "print(\"Best XGBoost parameters:\", xgb_tuned.best_params_)\n",
    "print(\"Best XGBoost AUC score:\", xgb_tuned.best_score_)\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model = XGBClassifier(\n",
    "    **xgb_tuned.best_params_,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "final_model.fit(X_train, y_train_binary)\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(final_model, 'sub_6_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ded2ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold evaluation:\n",
      "youden: thresh=0.3600, F1=0.5286, Prec=0.4437, Rec=0.6538, Combined=0.5076\n",
      "f1_optimal: thresh=0.3126, F1=0.5520, Prec=0.4036, Rec=0.8728, Combined=0.5051\n",
      "pr_balance: thresh=0.1000, F1=0.5342, Prec=0.0000, Rec=0.0000, Combined=0.5342\n",
      "Best threshold selected: 0.1000\n",
      "\n",
      "Final Optimal Threshold: 0.100000\n"
     ]
    }
   ],
   "source": [
    "# Load model from file\n",
    "final_model = joblib.load('sub_6_model.pkl')\n",
    "\n",
    "# Find optimal threshold for final model\n",
    "y_pred_proba_final = final_model.predict_proba(X_train)[:, 1]\n",
    "optimal_threshold_final = find_optimal_threshold(y_train_binary, y_pred_proba_final)\n",
    "\n",
    "print(f\"\\nFinal Optimal Threshold: {optimal_threshold_final:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c54f78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission_6_1.csv' created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on test set using optimal threshold\n",
    "test_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "# Save prediction probabilities\n",
    "submission_proba_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'song_popularity': test_pred_proba\n",
    "})\n",
    "submission_proba_df.to_csv(\"submission_6_prob_1.csv\", index=False)\n",
    "\n",
    "test_predictions = (test_pred_proba >= optimal_threshold_final).astype(int)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'song_popularity': test_predictions\n",
    "})\n",
    "\n",
    "# Save predictions\n",
    "file_output_name = \"submission_6_1.csv\"\n",
    "submission_df.to_csv(file_output_name, index=False)\n",
    "print(f\"Submission file '{file_output_name}' created!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
